{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Generated Attackers\n",
    "This example Notebook can be used to generate attackers for Mid-One CrunchDAO competition.\n",
    "- The notebook attempts to test the attackers on unseen data and iteratively improve on the next generated attacker.\n",
    "- When performance drops (based on PnL in unseen test data) a random scientific domain is injected into the prompt\n",
    "to try and give the LLM some \"creativity\" to produce a novel attacker idea.\n",
    "\n",
    "## Notes\n",
    "- The printed output from the example attacker in `initial_prompt` is used to gather outputs used in subsequent prompts. Be sure to check\n",
    "logic in `evaluate_script()` when printed output from the example attacker.\n",
    "- Increasing LLM temp above 0.0 seems to only introduce bugs into the generated attackers without much improvement in \"creativity\".\n",
    "- The example attacker uses Optuna for attacker param optimization. Subsets of total train streams are used on each iteration to\n",
    "try and speed up testing time. Adjust in example attacker `train()` if desired. Swap out other optimization package in example attacker as desired.\n",
    "    - Also, the example script standardizes the pnl for each tuning trial by number of messages in the subset of streams it's trained on, this way\n",
    "    we get a consistent metric across optimization trials. Not needed if the training batches are consistent across trials or the entire train set\n",
    "    is used for each trial.\n",
    "- OpenAI is used but Adalflow can handle other LLM clients/models easily.\n",
    "- Any OpenAI models weaker than gpt-4o model seem to be too buggy in generating attacker codes.\n",
    "\n",
    "## Non-standard Libraries\n",
    "- Uses [adalflow](https://github.com/SylphAI-Inc/AdalFlow) library for prompting and interacting with LLM. Next steps could be to utilize its\n",
    "built-in prompt optimization methods. In this Notebook the prompting is basic conditional logic.\n",
    "- Uses [optuna](https://github.com/optuna/optuna) for optimizing attacker parameters.\n",
    "    - The import and optimization setup is given to the LLM in the example attacker in `initial_prompt`\n",
    "\n",
    "## Before Running\n",
    "- Setup Mid-One CrunchDAO environment and place this notebook in model folder.\n",
    "- Create `.env` file and in CrunchDAO env model folder and add variable `OPENAI_API_KEY=\"****\"` or other LLM API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages required to run Notebook\n",
    "!pip install dotenv numpy openai adalflow optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import subprocess\n",
    "import traceback\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "\n",
    "from adalflow import Generator, Parameter, ParameterType\n",
    "from adalflow.components.model_client import OpenAIClient\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "model_client = OpenAIClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial prompt\n",
    "initial_prompt = '''\n",
    "You are a brilliant mathematical statistician and python expert. I need you to come up with creative \n",
    "\"Attackers\" that can predict the future price movements of a financial asset. There is a good working example\n",
    "below that uses the Hurst exponent to predict future price movements. Please use this as a starting point and\n",
    "come up with your own creative ideas. The goal is to maximize the profit on the test dataset.\n",
    "\n",
    "You response should only include a description and script code in this format (without the <> brackets):\n",
    "\n",
    "<Brief description of your attacker>\n",
    "```python\n",
    "<script code>\n",
    "```\n",
    "<blank>\n",
    "\n",
    "\n",
    "Rules for the script:\n",
    "\n",
    "1. MUST be a complete script that can be run from start to finish and return the profit value on the test dataset.\n",
    "2. MUST print the profit value exactly like so: print(f\"Profit (Test): {round(profit)}\")\n",
    "4. Trains for 100 n_trial for optimization in train() method.\n",
    "5. IMPORTANT: During tick() and predict() the model is not learning. The only \"training\"\n",
    "    is done in the train() method which optimizes the parameters of the Attacker model.\n",
    "6. In the objective() method is sure to predict across all streams. The stream index is the trial number.\n",
    "7. Should only need to modify the Attacker class and then the corresponding params in the train() and infer() methods.\n",
    "8. Ensures the script adheres to the competition's constraints, including the 20-millisecond tick() + predict() time limit.\n",
    "\n",
    "Example template of the script:\n",
    "\n",
    "```python\n",
    "import json\n",
    "import os\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from midone import HORIZON, Attacker\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import crunch\n",
    "\n",
    "\n",
    "class HurstAttacker(Attacker):\n",
    "\n",
    "    def __init__(self, window_size, upper_threshold, lower_threshold):\n",
    "        super().__init__()\n",
    "\n",
    "        # State\n",
    "        self.buffer = []\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # Parameters\n",
    "        self.upper_threshold = upper_threshold\n",
    "        self.lower_threshold = lower_threshold\n",
    "\n",
    "    def tick(self, x: float):\n",
    "        # Append the new data point to the buffer\n",
    "        if not np.isnan(x):\n",
    "            self.buffer.append(x)\n",
    "            if len(self.buffer) > self.window_size:\n",
    "                self.buffer.pop(0)  # Remove the oldest data point\n",
    "\n",
    "    def predict(self, horizon=HORIZON) -> float:\n",
    "        if len(self.buffer) < self.window_size:\n",
    "            return 0  # Not enough data to make a prediction\n",
    "\n",
    "        # Estimate the Hurst exponent\n",
    "        hurst_exponent = self._estimate_hurst_exponent(np.array(self.buffer))\n",
    "\n",
    "        if hurst_exponent > self.upper_threshold:\n",
    "            return 1  # Predict upward movement\n",
    "        elif hurst_exponent < self.lower_threshold:\n",
    "            return -1  # Predict downward movement\n",
    "        else:\n",
    "            return 0  # Hold\n",
    "\n",
    "    def _estimate_hurst_exponent(self, time_series: np.ndarray) -> float:\n",
    "        \"\"\"Estimate the Hurst exponent using the rescaled range (R/S) method.\"\"\"\n",
    "\n",
    "        N = len(time_series)\n",
    "        if N < 20:\n",
    "            return 0.5  # Not enough data\n",
    "\n",
    "        # Calculate the mean and subtract it from the series\n",
    "        mean_ts = np.mean(time_series)\n",
    "        centered_ts = time_series - mean_ts\n",
    "\n",
    "        # Calculate the cumulative deviate series\n",
    "        cumulative_deviation = np.cumsum(centered_ts)\n",
    "\n",
    "        # Range (R)\n",
    "        R = np.max(cumulative_deviation) - np.min(cumulative_deviation)\n",
    "\n",
    "        # Standard deviation (S)\n",
    "        S = np.std(time_series)\n",
    "\n",
    "        if S == 0:\n",
    "            return 0.5  # Avoid division by zero\n",
    "\n",
    "        # Rescaled range (R/S)\n",
    "        rescaled_range = R / S\n",
    "\n",
    "        # Estimate Hurst exponent\n",
    "        hurst_exponent = np.log(rescaled_range) / np.log(N)\n",
    "\n",
    "        # Ensure H is between 0 and 1\n",
    "        hurst_exponent = max(min(hurst_exponent, 1), 0)\n",
    "\n",
    "        return hurst_exponent\n",
    "\n",
    "\n",
    "def attacker_performance(\n",
    "    streams: typing.List[typing.Iterable[dict]],\n",
    "    params: typing.Dict,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    params: dict with keys 'window_size', 'upper_threshold', 'lower_threshold'\n",
    "    streams: Supplies a collection of individual streams\n",
    "    \"\"\"\n",
    "    window_size = int(params[\"window_size\"])\n",
    "    upper_threshold = params[\"upper_threshold\"]\n",
    "    lower_threshold = params[\"lower_threshold\"]\n",
    "\n",
    "    total_profit = 0\n",
    "    std_profit = 0\n",
    "\n",
    "    for stream in streams:\n",
    "        # Reset the attacker each stream\n",
    "        attacker = HurstAttacker(\n",
    "            window_size=window_size,\n",
    "            upper_threshold=upper_threshold,\n",
    "            lower_threshold=lower_threshold,\n",
    "        )\n",
    "\n",
    "        # Run it over the stream\n",
    "        for message in stream:\n",
    "            x = message[\"x\"]\n",
    "            attacker.tick_and_predict(x=x, horizon=HORIZON)\n",
    "\n",
    "        pnl = attacker.pnl.summary()\n",
    "        total_profit += pnl[\"total_profit\"]\n",
    "        # Standardize profit by stream by dividing by the number possible trades\n",
    "        # in the stream. Useful when tuning parameters after each stream.\n",
    "        if \"current_ndx\" in pnl:\n",
    "            stream_std_profit = pnl[\"total_profit\"] / pnl[\"current_ndx\"]\n",
    "            std_profit += stream_std_profit\n",
    "        else:\n",
    "            std_profit += 0\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Using window_size={window_size}, upper_threshold={upper_threshold}, lower_threshold={lower_threshold}, total profit={total_profit}\"\n",
    "        )\n",
    "\n",
    "    # Return total profit for maximization\n",
    "    return total_profit, std_profit\n",
    "\n",
    "\n",
    "def get_parameter_file_path(model_directory_path: str):\n",
    "    return os.path.join(model_directory_path, \"mid_one_model.json\")\n",
    "\n",
    "\n",
    "def train(\n",
    "    streams: typing.List[typing.Iterable[dict]],\n",
    "    model_directory_path: str,\n",
    "):\n",
    "    best_params_overall = None\n",
    "    best_profit_overall = -np.inf\n",
    "\n",
    "    # Initialize parameters\n",
    "    initial_params = {\n",
    "        \"window_size\": 79,\n",
    "        \"upper_threshold\": 0.6187887621347552,\n",
    "        \"lower_threshold\": 0.1910861914485038,\n",
    "    }\n",
    "\n",
    "    # Total number of trials\n",
    "    n_trials = len(streams) - 1\n",
    "\n",
    "    # Create an Optuna study\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    # Enqueue initial parameter values\n",
    "    study.enqueue_trial(initial_params)\n",
    "\n",
    "    # Define the objective function for Optuna\n",
    "    def objective(trial):\n",
    "        # Pick random stream to optimize on\n",
    "        trial_index_list = np.random.choice(len(streams), 10, replace=False)\n",
    "        # Only keep trial_index_list elements from streams list\n",
    "        subset_streams = [streams[i] for i in trial_index_list]\n",
    "\n",
    "        window_size = trial.suggest_int(\"window_size\", 20, 100)\n",
    "        upper_threshold = trial.suggest_float(\"upper_threshold\", 0.5, 1.0)\n",
    "        lower_threshold = trial.suggest_float(\"lower_threshold\", 0.0, 0.5)\n",
    "\n",
    "        # Ensure lower_threshold is less than upper_threshold\n",
    "        if lower_threshold >= upper_threshold:\n",
    "            return float(\n",
    "                \"-inf\"\n",
    "            )  # Return negative infinity to indicate invalid parameters\n",
    "\n",
    "        params = {\n",
    "            \"window_size\": window_size,\n",
    "            \"upper_threshold\": upper_threshold,\n",
    "            \"lower_threshold\": lower_threshold,\n",
    "        }\n",
    "\n",
    "        # Evaluate the attacker on the current stream\n",
    "        profit, std_profit = attacker_performance(\n",
    "            params=params, streams=subset_streams, verbose=False\n",
    "        )\n",
    "\n",
    "        return std_profit\n",
    "\n",
    "    # Run the optimization\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_std_profit = study.best_value\n",
    "\n",
    "    print(f\"Best standardized profit: {best_std_profit}, best params: {best_params}\")\n",
    "\n",
    "    # Save the best parameters\n",
    "    parameter_file_path = get_parameter_file_path(model_directory_path)\n",
    "    with open(parameter_file_path, \"w\") as fd:\n",
    "        json.dump(best_params, fd)\n",
    "        print(f\"Saved best parameters to {parameter_file_path}\")\n",
    "\n",
    "    # Check we can load it again\n",
    "    try:\n",
    "        with open(parameter_file_path, \"r\") as fd:\n",
    "            params = json.load(fd)\n",
    "            print(f\"Loaded Best Parameters: {params}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Parameter reload test failed: {e}\")\n",
    "\n",
    "\n",
    "def infer(\n",
    "    stream: typing.Iterator[dict],\n",
    "    model_directory_path: str,\n",
    "):\n",
    "    # Load the best parameters\n",
    "    parameter_file_path = get_parameter_file_path(model_directory_path)\n",
    "    with open(parameter_file_path, \"r\") as fd:\n",
    "        params = json.load(fd)\n",
    "        window_size = int(params[\"window_size\"])\n",
    "        upper_threshold = params[\"upper_threshold\"]\n",
    "        lower_threshold = params[\"lower_threshold\"]\n",
    "\n",
    "    # Instantiate your attacker\n",
    "    attacker = HurstAttacker(\n",
    "        window_size=window_size,\n",
    "        upper_threshold=upper_threshold,\n",
    "        lower_threshold=lower_threshold,\n",
    "    )\n",
    "\n",
    "    # NOTE: DO NOT REMOVE THIS YIELD\n",
    "    # Signals to the system that your attacker is initialized and ready.\n",
    "    yield\n",
    "\n",
    "    for message in stream:\n",
    "        decision = attacker.tick_and_predict(message[\"x\"])\n",
    "\n",
    "        # Be sure to yield, even if the decision is zero.\n",
    "        yield decision\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the data\n",
    "    crunch = crunch.load_notebook()\n",
    "    x_train, x_test = crunch.load_streams()\n",
    "\n",
    "    # Train the model\n",
    "    train(\n",
    "        streams=x_train,\n",
    "        model_directory_path=\"resources/\",\n",
    "    )\n",
    "\n",
    "    # Load parameters for testing\n",
    "    parameter_file_path = get_parameter_file_path(\"resources/\")\n",
    "    with open(parameter_file_path, \"r\") as fd:\n",
    "        params = json.load(fd)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    profit, std_profit = attacker_performance(x_test, params=params, verbose=True)\n",
    "    print(f\"Profit (Test): {round(profit)}\")\n",
    "\n",
    "```\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Parameter object for the prompt\n",
    "prompt_param = Parameter(\n",
    "    data=initial_prompt,\n",
    "    role_desc=\"Prompt for generating Python scripts for Attacker models\",\n",
    "    requires_opt=True,\n",
    "    param_type=ParameterType.PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator with the prompt parameter\n",
    "generator = Generator(\n",
    "    model_client=model_client,\n",
    "    model_kwargs={\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"max_tokens\": 16384,\n",
    "        \"temperature\": 0.0,\n",
    "    },\n",
    "    prompt_kwargs={\n",
    "        \"input_str\": prompt_param.data\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_script(script_content, script_path):\n",
    "    \"\"\"\n",
    "    Evaluate the provided Python script by running it and extracting the PnL value from the output.\n",
    "\n",
    "    Args:\n",
    "        script_content (str): The content of the Python script to evaluate.\n",
    "        script_path (str): The path to save the script to.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the PnL value, a boolean indicating if the process timed out,\n",
    "            the traceback error message (if any), and the parameter info line from the script output.\n",
    "    \"\"\"\n",
    "    # Save the script to a temporary file\n",
    "    with open(script_path, \"w\") as file:\n",
    "        file.write(script_content)\n",
    "\n",
    "    # Initialize the return variables\n",
    "    result = []\n",
    "    is_timeout = False\n",
    "    traceback_error = None\n",
    "    param_info = None\n",
    "    try:\n",
    "        process = subprocess.Popen(\n",
    "            [\"python3\", script_path],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "        )\n",
    "        # Wait for the process to complete within the specified timeout\n",
    "        stdout, _ = process.communicate(timeout=60 * 20)\n",
    "        result.extend(stdout.splitlines())\n",
    "        for line in result:\n",
    "            print(line)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        process.kill()\n",
    "        is_timeout = True\n",
    "        log.warning(\"Process timed out and was killed.\")\n",
    "    except Exception as e:\n",
    "        log.error(f\"Error occurred: {e}\")\n",
    "        traceback_error = traceback.format_exc()\n",
    "\n",
    "    # Extract PnL from the script's output\n",
    "    pnl = None\n",
    "    for line in result:\n",
    "        if line.startswith(\"Profit (Test): \"):\n",
    "            log.debug(f\"PnL line: {line}\")\n",
    "            pnl = float(line.split(\": \")[1].strip())\n",
    "        elif line.startswith(\"Using \"):\n",
    "            log.debug(f\"Using line: {line}\")\n",
    "            param_info = line\n",
    "\n",
    "    if pnl is None:\n",
    "        raise ValueError(\"PnL not found in script output.\")\n",
    "\n",
    "    return pnl, is_timeout, traceback_error, param_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domains injected into prompt to spur some new ideas from the LLM\n",
    "science_domains = [\n",
    "    \"Astrophysics\",\n",
    "    \"Biochemistry\",\n",
    "    \"Quantum Mechanics\",\n",
    "    \"Ecology\",\n",
    "    \"Neuroscience\",\n",
    "    \"Genetics\",\n",
    "    \"Geology\",\n",
    "    \"Meteorology\",\n",
    "    \"Oceanography\",\n",
    "    \"Robotics\",\n",
    "    \"Artificial Intelligence\",\n",
    "    \"Materials Science\",\n",
    "    \"Immunology\",\n",
    "    \"Anthropology\",\n",
    "    \"Linguistics\",\n",
    "    \"Paleontology\",\n",
    "    \"Nanotechnology\",\n",
    "    \"Biophysics\",\n",
    "    \"Cognitive Science\",\n",
    "    \"Environmental Science\",\n",
    "    \"Astronomy\",\n",
    "    \"Evolutionary Biology\",\n",
    "    \"Chemical Engineering\",\n",
    "    \"Nuclear Physics\",\n",
    "    \"Forensic Science\",\n",
    "    \"Pharmacology\",\n",
    "    \"Hydrology\",\n",
    "    \"Sociology\",\n",
    "    \"Cybersecurity\",\n",
    "    \"Agronomy\",\n",
    "    \"Microbiology\",\n",
    "    \"Virology\",\n",
    "    \"Molecular Biology\",\n",
    "    \"Cell Biology\",\n",
    "    \"Systems Biology\",\n",
    "    \"Developmental Biology\",\n",
    "    \"Marine Biology\",\n",
    "    \"Bioinformatics\",\n",
    "    \"Biotechnology\",\n",
    "    \"Theoretical Physics\",\n",
    "    \"Condensed Matter Physics\",\n",
    "    \"Plasma Physics\",\n",
    "    \"Particle Physics\",\n",
    "    \"Optics\",\n",
    "    \"Acoustics\",\n",
    "    \"Thermodynamics\",\n",
    "    \"Classical Mechanics\",\n",
    "    \"Statistical Mechanics\",\n",
    "    \"Applied Mathematics\",\n",
    "    \"Computational Science\",\n",
    "    \"Information Theory\",\n",
    "    \"Cryptography\",\n",
    "    \"Data Science\",\n",
    "    \"Machine Learning\",\n",
    "    \"Game Theory\",\n",
    "    \"Operations Research\",\n",
    "    \"Control Systems\",\n",
    "    \"Electrical Engineering\",\n",
    "    \"Mechanical Engineering\",\n",
    "    \"Civil Engineering\",\n",
    "    \"Aerospace Engineering\",\n",
    "    \"Biomedical Engineering\",\n",
    "    \"Environmental Engineering\",\n",
    "    \"Food Science\",\n",
    "    \"Nutrition Science\",\n",
    "    \"Public Health\",\n",
    "    \"Epidemiology\",\n",
    "    \"Veterinary Medicine\",\n",
    "    \"Dentistry\",\n",
    "    \"Psychology\",\n",
    "    \"Psychiatry\",\n",
    "    \"Social Work\",\n",
    "    \"Political Science\",\n",
    "    \"Economics\",\n",
    "    \"Demography\",\n",
    "    \"Archaeology\",\n",
    "    \"Education Research\",\n",
    "    \"Urban Planning\",\n",
    "    \"Forestry\",\n",
    "    \"Zoology\",\n",
    "    \"Botany\",\n",
    "    \"Entomology\",\n",
    "    \"Ornithology\",\n",
    "    \"Herpetology\",\n",
    "    \"Ichthyology\",\n",
    "    \"Climatology\",\n",
    "    \"Glaciology\",\n",
    "    \"Volcanology\",\n",
    "    \"Seismology\",\n",
    "    \"Mineralogy\",\n",
    "    \"Petrology\",\n",
    "    \"Stratigraphy\",\n",
    "    \"Geophysics\",\n",
    "    \"Geochemistry\",\n",
    "    \"Astrochemistry\",\n",
    "    \"Astrogeology\",\n",
    "    \"Exoplanetology\",\n",
    "    \"Cosmology\",\n",
    "    \"Space Science\",\n",
    "    \"Atmospheric Science\",\n",
    "    \"Quantum Computing\",\n",
    "    \"Speech Pathology\",\n",
    "    \"Kinesiology\",\n",
    "    \"Biomechanics\",\n",
    "    \"Hydrogeology\",\n",
    "    \"Geoinformatics\",\n",
    "    \"Remote Sensing\",\n",
    "    \"Spectroscopy\",\n",
    "    \"Toxicology\",\n",
    "    \"Structural Engineering\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization loop\n",
    "num_iterations = 500\n",
    "best_pnl = -np.inf\n",
    "best_description = \"\"\n",
    "best_python_script = \"\"\n",
    "previous_pnl = -np.inf\n",
    "previous_description = \"\"\n",
    "previous_python_script = \"\"\n",
    "\n",
    "# Initialize prompt feedback (empty)\n",
    "feedback = \"\"\n",
    "param_info = \"\"\n",
    "for iteration in range(num_iterations):\n",
    "    # Save prompt to file for debugging\n",
    "    with open(f\"last_prompt_temp.txt\", \"w\") as file:\n",
    "        file.write(prompt_param.data + feedback)\n",
    "        \n",
    "    # Generate the Python script\n",
    "    output = generator(prompt_kwargs={\"input_str\": prompt_param.data + feedback})\n",
    "\n",
    "    # Extract description and code\n",
    "    try:\n",
    "        description, code_block = output.data.strip().split(\"```\", 1)\n",
    "        python_script = code_block.strip().lstrip(\"python\").rstrip(\"```\").strip()\n",
    "    except ValueError:\n",
    "        log.error(\"Failed to parse the output from the generator.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"LLM Attacker Description:\\n{description}\")\n",
    "\n",
    "    # Evaluate the script to obtain PnL\n",
    "    script_path = f\"attacker_{iteration:03d}.py\"\n",
    "    is_timeout = False\n",
    "    traceback_error = None\n",
    "    try:\n",
    "        pnl, is_timeout, traceback_error, param_info = evaluate_script(\n",
    "            python_script, script_path\n",
    "        )\n",
    "        print(f\"Iteration {iteration + 1}: PnL = {pnl}\")\n",
    "    except Exception as e:\n",
    "        log.error(f\"Iteration {iteration + 1}: Evaluation failed with error: {e}\")\n",
    "        pnl = None\n",
    "\n",
    "    # Update the prompt based on PnL\n",
    "    if traceback_error:\n",
    "        feedback = (\n",
    "            \"\\n\\n---\\n\\nIMPORTANT: Everything above was the initial prompt. \"\n",
    "            \"Here is the feedback from your last attempt specifically:\\n\\n\"\n",
    "            \"The script execution failed. Please fix using the traceback below:\\n\"\n",
    "            f\"{traceback_error}\"\n",
    "        )\n",
    "    elif is_timeout:\n",
    "        feedback = (\n",
    "            \"\\n\\n---\\n\\nIMPORTANT: Everything above was the initial prompt. \"\n",
    "            \"Here is the feedback from your last attempt specifically:\\n\\n\"\n",
    "            \"The script execution timed out. Ensure the tick() and predict() methods combined \"\n",
    "            \"can run in 20 milliseconds or less for each tick in the stream.\"\n",
    "        )\n",
    "    elif pnl is None:\n",
    "        # Handle cases where PnL could not be evaluated\n",
    "        feedback = (\n",
    "            \"\\n\\n---\\n\\nIMPORTANT: Everything above was the initial prompt. \"\n",
    "            \"Here is the feedback from your last attempt specifically:\\n\\n\"\n",
    "            \"The script execution failed. Please fix using the traceback below:\\n\"\n",
    "            f\"{traceback_error}\"\n",
    "        )\n",
    "    elif pnl > best_pnl:\n",
    "        feedback = (\n",
    "            f\"\\n\\n---\\n\\nIMPORTANT: Everything above was the initial prompt. \"\n",
    "            \"Here is the feedback from your last attempt specifically:\\n\\n\"\n",
    "            f\"This was your best model yet! The PnL was {pnl} compared to your previous best of {best_pnl}. \"\n",
    "            f\"Try a similar strategy but with a slight tweak :) For reference, your best attacker description was: \"\n",
    "            f\"'{description.strip()}'. Your best Python script was:\\n\\n```python\\n{best_python_script}\\n```\"\n",
    "        )\n",
    "        # Update best PnL for model to remember\n",
    "        best_pnl = pnl\n",
    "        best_description = description\n",
    "        best_python_script = python_script\n",
    "    elif pnl <= previous_pnl:\n",
    "        # Pick a random science domain to suggest\n",
    "        science_domain = np.random.choice(science_domains)\n",
    "        feedback = (\n",
    "            f\"\\n\\n---\\n\\nIMPORTANT: Everything above was the initial prompt. \"\n",
    "            \"Here is the feedback from your last attempt specifically:\\n\\n\"\n",
    "            f\"This PnL of {pnl} was not an improvement over the last of {previous_pnl}. \"\n",
    "            f\"Please try applying a totally different strategy inspired by the field of {science_domain}. \"\n",
    "            f\"For reference, your previous attacker description was: '{previous_description.strip()}'. \"\n",
    "            f\"Your previous Python script was:\\n\\n```python\\n{previous_python_script}\\n```\"\n",
    "        )\n",
    "    elif pnl > previous_pnl:\n",
    "        feedback = (\n",
    "            f\"\\n\\n---\\n\\nIMPORTANT: Everything above was the initial prompt. \"\n",
    "            \"Here is the feedback from your last attempt specifically:\\n\\n\"\n",
    "            f\"This PnL of {pnl} was an improvement from the last of {previous_pnl}. \"\n",
    "            f\"Your best so far is {best_pnl}. Keep up the good work and see if you can push the boundaries even further! \"\n",
    "            f\"For reference, your previous attacker description was: '{previous_description.strip()}'. \"\n",
    "            f\"Your previous Python script was:\\n\\n```python\\n{previous_python_script}\\n```\"\n",
    "        )\n",
    "\n",
    "    # Append best pnl and description to results.txt\n",
    "    with open(\"results.txt\", \"a\") as file:\n",
    "        file.write(\n",
    "            f\"Iteration {iteration + 1}: PnL = {pnl}\\nDescription: {description}\\n{param_info}\\n\"\n",
    "        )\n",
    "\n",
    "    # Record the previous PnL for model to remember\n",
    "    if pnl is not None:\n",
    "        previous_pnl = pnl\n",
    "        previous_description = description\n",
    "        previous_python_script = python_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
